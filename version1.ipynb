{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as ctb\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, cross_validate, GridSearchCV, StratifiedKFold\n",
    "from sklearn.decomposition import PCA\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def offline_evaluation(pred):\n",
    "    X_train = pd.read_csv(\"data/train.csv\")\n",
    "    X_test = pd.read_csv(\"data/test.csv\")\n",
    "    original_data = pd.read_csv(\"original_data/covtype.csv\")\n",
    "    X_train.drop(\"Id\", axis=1, inplace=True)\n",
    "    test_ID = X_test[\"Id\"]\n",
    "    X_test.drop(\"Id\", axis=1, inplace=True)\n",
    "    y_train = np.array(X_train['Cover_Type'])\n",
    "    X_train.drop('Cover_Type', axis=1, inplace=True)\n",
    "    num_train = X_train.shape[0]\n",
    "    all_data = pd.concat([X_train, X_test])\n",
    "    all_data = pd.merge(all_data, original_data, how=\"left\")\n",
    "    original_y_train = all_data[\"Cover_Type\"][:num_train]\n",
    "    original_y_test = all_data[\"Cover_Type\"][num_train:]\n",
    "    assert np.all(original_y_train == y_train)\n",
    "    print(accuracy_score(original_y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain test set class distribution through probing the leaderboard \n",
    "class_weight = {1: 0.370530,\n",
    "                2: 0.496810,\n",
    "                3: 0.059365,\n",
    "                4: 0.001037,\n",
    "                5: 0.012958,\n",
    "                6: 0.026873,\n",
    "                7: 0.032427}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_accuracy_score(y_true, y_pred):\n",
    "    return accuracy_score(y_true, y_pred, sample_weight=[class_weight[label] for label in y_true])\n",
    "balanced_accuracy_scorer = make_scorer(balanced_accuracy_score, greater_is_better=True)\n",
    "my_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"data/train.csv\")\n",
    "X_test = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(\"Id\", axis=1, inplace=True)\n",
    "test_ID = X_test[\"Id\"]\n",
    "X_test.drop(\"Id\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(X_train['Cover_Type'])\n",
    "X_train.drop('Cover_Type', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(X_train.loc[:, \"Wilderness_Area1\": \"Wilderness_Area4\"].sum(axis=1) == 1)\n",
    "assert np.all(X_train.loc[:, \"Soil_Type1\": \"Soil_Type40\"].sum(axis=1) == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = X_train.shape[0]\n",
    "all_data = pd.concat([X_train, X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(581012, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=0.95).fit(all_data)\n",
    "pca_trans = pca.transform(all_data)\n",
    "pca_trans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(pca_trans.shape[1]):\n",
    "    all_data[\"pca\" + str(i)] = pca_trans[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"Degree_To_Hydrology\"] = (np.arctan((all_data[\"Vertical_Distance_To_Hydrology\"] + np.finfo(\"float64\").eps) /\n",
    "                                             (all_data[\"Horizontal_Distance_To_Hydrology\"] + np.finfo(\"float64\").eps)))\n",
    "all_data[\"Distance_to_Hydrology\"] = (np.square(all_data[\"Vertical_Distance_To_Hydrology\"]) +\n",
    "                                               np.square(all_data[\"Vertical_Distance_To_Hydrology\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hillshade_cols = [\"Hillshade_9am\", \"Hillshade_Noon\", \"Hillshade_3pm\"]\n",
    "all_data[\"Hillshade_mean\"] = all_data[hillshade_cols].mean(axis=1)\n",
    "all_data[\"Hillshade_std\"] = all_data[hillshade_cols].std(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"Horizontal_Distance_To_Hydrology\",  \"Horizontal_Distance_To_Roadways\", \"Horizontal_Distance_To_Fire_Points\"]\n",
    "names = [\"H\", \"R\", \"F\"]\n",
    "for i in range(len(cols)):\n",
    "    for j in range(i + 1, len(cols)):\n",
    "        all_data[\"Horizontal_Distance_combination_\" + names[i] + names[j] + \"_1\"] = all_data[cols[i]] + all_data[cols[j]]\n",
    "        all_data[\"Horizontal_Distance_combination_\" + names[i] + names[j] + \"_2\"] = (all_data[cols[i]] + all_data[cols[j]]) / 2\n",
    "        all_data[\"Horizontal_Distance_combination_\" + names[i] + names[j] + \"_3\"] = all_data[cols[i]] - all_data[cols[j]]\n",
    "        all_data[\"Horizontal_Distance_combination_\" + names[i] + names[j] + \"_4\"] = np.abs(all_data[cols[i]] - all_data[cols[j]])\n",
    "all_data[\"Horizontal_Distance_mean\"] = all_data[cols].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"Elevation_Hydrology_1\"] = all_data[\"Elevation\"] + all_data[\"Vertical_Distance_To_Hydrology\"]\n",
    "all_data[\"Elevation_Hydrology_2\"] = all_data[\"Elevation\"] - all_data[\"Vertical_Distance_To_Hydrology\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = all_data[:num_train]\n",
    "X_test = all_data[num_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n",
      "0.8021838712962964 0.011155906736295742\n"
     ]
    }
   ],
   "source": [
    "clf = ExtraTreesClassifier(n_estimators=250, random_state=0, n_jobs=-1)\n",
    "scores = cross_validate(clf, X_train, y_train, cv=my_cv,\n",
    "                        fit_params={\"sample_weight\":[class_weight[label] for label in y_train]},\n",
    "                        scoring=balanced_accuracy_scorer, return_train_score=True)\n",
    "print(np.mean(scores[\"train_score\"]), np.std(scores[\"train_score\"]))\n",
    "print(np.mean(scores[\"test_score\"]), np.std(scores[\"test_score\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8131145165508613\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train, sample_weight=[class_weight[label] for label in y_train])\n",
    "pred = clf.predict(X_test)\n",
    "offline_evaluation(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgtm_class_weight = {i: w for i, w in enumerate(class_weight.values())}\n",
    "# clf = lgb.LGBMClassifier(n_estimators=600, random_state=0, n_jobs=-1, class_weight=lgtm_class_weight)\n",
    "# scores = cross_validate(clf, X_train, y_train, cv=my_cv,\n",
    "#                         scoring=balanced_accuracy_scorer, return_train_score=True)\n",
    "# print(np.mean(scores[\"train_score\"]), np.std(scores[\"train_score\"]))\n",
    "# print(np.mean(scores[\"test_score\"]), np.std(scores[\"test_score\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf.fit(X_train, y_train)\n",
    "# pred = clf.predict(X_test)\n",
    "# offline_evaluation(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n",
      "0.7931799476851852 0.007347016069991456\n"
     ]
    }
   ],
   "source": [
    "clf = lgb.LGBMClassifier(n_estimators=600, random_state=0, n_jobs=-1)\n",
    "scores = cross_validate(clf, X_train, y_train, cv=my_cv,\n",
    "                        fit_params={\"sample_weight\":[class_weight[label] for label in y_train]},\n",
    "                        scoring=balanced_accuracy_scorer, return_train_score=True)\n",
    "print(np.mean(scores[\"train_score\"]), np.std(scores[\"train_score\"]))\n",
    "print(np.mean(scores[\"test_score\"]), np.std(scores[\"test_score\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8122645310412587\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train, sample_weight=[class_weight[label] for label in y_train])\n",
    "pred = clf.predict(X_test)\n",
    "offline_evaluation(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = ExtraTreesClassifier(n_estimators=250, random_state=0, n_jobs=-1)\n",
    "clf2 = lgb.LGBMClassifier(n_estimators=600, random_state=0, n_jobs=-1)\n",
    "clf = StackingCVClassifier(classifiers=[clf1, clf2],\n",
    "                           meta_classifier=xgb.XGBClassifier(n_estimators=50, random_state=0, n_jobs=-1),\n",
    "                           cv=my_cv, random_state=0, use_probas=True, use_features_in_secondary=True)\n",
    "clf.fit(X_train, y_train, sample_weight=[class_weight[label] for label in y_train])\n",
    "pred = clf.predict(X_test)\n",
    "submission = pd.DataFrame({'Id':test_ID, 'Cover_Type':pred},\n",
    "                          columns=['Id', 'Cover_Type'])\n",
    "submission.to_csv(\"submit/v1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8621574434697787\n"
     ]
    }
   ],
   "source": [
    "offline_evaluation(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "work"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
